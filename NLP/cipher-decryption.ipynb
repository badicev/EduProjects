{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                 \n",
    "                                      Cipher Decryption  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><image src=\"https://wallpaperaccess.com/full/1820624.jpg\" width=2200 height=400></small>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>*What is a cipher?*\n",
    "* Encode + Decode a message\n",
    "\n",
    "*Language Modeling*\n",
    "* What is the probability of this sentence?\n",
    "* Can generate new sentences (poetry, article spinning)\n",
    "\n",
    "*Genetic algorithm/evolutionary algorithm*\n",
    "* Optimization based on biological evolution\n",
    "\n",
    "*Our decoded message should have the highest likelihood if the model is trained on the English language*\n",
    "* A message not in English should have a smaller likelihood(\"maximum likelihood\")\n",
    "\n",
    "</small>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><p>Build a model that assigns high probability to real words/sentences, low probability to unreal words/sentences</p><small/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MYMODEL(\"I love gaming\") -> high probability | decrypt the message correctly<br>\n",
    "* MYMODEL(\"U kucw fanlbf\") -> low probability | decrypt the message incorrectly<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>N-grams: A sequence of N tokens \n",
    "\n",
    "N = 1: Unigram<br>\n",
    "N = 2: Bigram<br>\n",
    "N = 3: Trigram<br>\n",
    "\n",
    "Markov Models: A Markov model is a model of language that makes the assumption that the next word in a sentence only depends on the previous word (or letter!)<br>\n",
    " <small/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* p(A | B) = p(A, B) / p(B)<br>\n",
    "\n",
    "* p(A | B) = # of times A appears after B (BA) / # of times B appears (B)<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If we have V letters in the alphabet, then we have V^2 bigrams, V^3 trigrams, etc.<br>\n",
    "- AA, AB, AC, ..., AZ\n",
    "- BA, BB, BC, ..., BZ\n",
    "- ....\n",
    "- ZA, ZB, ZC, ..., ZZ\n",
    "\n",
    "Therefore, 26 * 26 = 676 bigrams, 26 * 26 * 26 = 17576 trigrams, etc.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“When I consider the short duration of my life, swallowed up in the eternity before and after, the little space which I fill, and even can see, engulfed in the infinite immensity of spaces of which I am ignorant, and which know me not, I am frightened, and am astonished at being here rather than there; for there is no reason why here rather than there, why now rather than then. Who has put me here? By whose order and direction have this place and time been allotted to me? Memoria hospitis unius diei prætereuntis.(The remembrance of a guest of one day that passeth by|Douay-Rheims)”"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Packages</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import textwrap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create substitution cipher<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the key and the value for the cipher\n",
    "\n",
    "letters1 = list(string.ascii_lowercase) #returns a list of all the letters in the alphabet\n",
    "letters2 = list(string.ascii_lowercase)\n",
    "\n",
    "letters1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "\n",
    "#Shuffle the values of the letters2 list\n",
    "random.shuffle(letters2)\n",
    "\n",
    "#populate the mapping dictionary\n",
    "for k, v in zip(letters1,letters2):\n",
    "    mapping[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g',\n",
       " 'x',\n",
       " 'k',\n",
       " 'e',\n",
       " 's',\n",
       " 'm',\n",
       " 'q',\n",
       " 'v',\n",
       " 'z',\n",
       " 'r',\n",
       " 'o',\n",
       " 'i',\n",
       " 'f',\n",
       " 'w',\n",
       " 'u',\n",
       " 'n',\n",
       " 'd',\n",
       " 'j',\n",
       " 'p',\n",
       " 'h',\n",
       " 'b',\n",
       " 'y',\n",
       " 'a',\n",
       " 'l',\n",
       " 'c',\n",
       " 't']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to decrypt the message! We will use a substitution cipher to do this. A substitution cipher is a cipher where each letter in the alphabet is replaced by another letter in the alphabet. For example, we could replace every A with a B, every B with a C, etc. This is a very simple cipher, but it is still difficult to break without knowing the key. We will use a genetic algorithm to find the key."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Language Model (Metamorphosis by Franz Kafka) and log-likelihood function<b/>\n",
    "<href>https://www.gutenberg.org/ebooks/5200</href> -> path:NLP\\data\\meta.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Markov Matrix\n",
    "\n",
    "M = np.ones((26,26)) #26 letters in the alphabet\n",
    "#add one to each element to avoid zero probabilities\n",
    "#add one smoothing\n",
    "\n",
    "#initial state distribution\n",
    "pi = np.zeros(26)\n",
    "\n",
    "#update the matrix\n",
    "def update_transition(starting_letter, ending_letter):\n",
    "    #ord('a') = 97, ord('b') = 98, ord('c') = 99, etc.\n",
    "    i = ord(starting_letter) - 97 #ord: returns the unicode code point for a one-character string\n",
    "    j = ord(ending_letter) - 97\n",
    "    M[i,j] += 1\n",
    "    \n",
    "#Note: Everything stored in the computer is stored as binary code, zeros and ones. (base-2 numeral system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update initial state distribution\n",
    "def update_pi(letter):\n",
    "    i = ord(letter) - 97\n",
    "    pi[i] += 1\n",
    "    \n",
    "def get_word_probability(word):\n",
    "    #print(\"word:\", word)\n",
    "    i = ord(word[0]) - 97\n",
    "    log_prob = np.log(pi[i])\n",
    "    \n",
    "    for letter in word[1:]:\n",
    "        j = ord(letter) - 97\n",
    "        log_prob  += np.log(M[i,j])\n",
    "        i = j #update the index\n",
    "        \n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability of a sentence (sequence of words)\n",
    "def get_sentence_probability(words):\n",
    "    #if input is a string, convert it to a list of words (array of tokens)\n",
    "    if type(words) == str:\n",
    "        words = words.split()\n",
    "        \n",
    "    log_prob = 0\n",
    "    for word in words:\n",
    "        log_prob += get_word_probability(word)\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data/meta.txt', encoding=\"utf-8\") as f:\n",
    "    meta = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace non-alphabetic characters with spaces\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "#split the text into words\n",
    "words = regex.sub(' ', meta).lower().split()\n",
    "words[2:7]\n",
    "\n",
    "#remove empty strings\n",
    "words = [w for w in words if w != '']\n",
    "\n",
    "#update the model\n",
    "for word in words:\n",
    "    #first letter\n",
    "    char0 = word[0]\n",
    "    update_pi(char0)\n",
    "    \n",
    "    #rest of the letters\n",
    "    for char1 in word[1:]:\n",
    "        update_transition(char0, char1)\n",
    "        char0 = char1\n",
    "        \n",
    "#normalize the probabilities\n",
    "pi /= pi.sum()\n",
    "M /= M.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Encoding and Decoding functions<b/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_message = '''When I consider the short duration of my life, swallowed up\n",
    "in the eternity before and after, the little space which I fill, and even can see,\n",
    "engulfed in the infinite immensity of spaces of which I am ignorant, and which know me not,\n",
    "I am frightened, and am astonished at being here rather than there; for there is no reason\n",
    "why here rather than there, why now rather than then. Who has put me here? By whose order \n",
    "and direction have this place and time been allotted to me? The remembrance of a guest of \n",
    "one day that passeth by'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When I consider the short duration of my life, swallowed up\\nin the eternity before and after, the little space which I fill, and even can see,\\nengulfed in the infinite immensity of spaces of which I am ignorant, and which know me not,\\nI am frightened, and am astonished at being here rather than there; for there is no reason\\nwhy here rather than there, why now rather than then. Who has put me here? By whose order \\nand direction have this place and time been allotted to me? The remembrance of a guest of \\none day that passeth by'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the message\n",
    "def encode(message):\n",
    "    message = message.lower()\n",
    "    #replace non-alphabetic characters with spaces\n",
    "    message = regex.sub(' ', message)\n",
    "    \n",
    "    #encoded message\n",
    "    encrpted_message = []\n",
    "    for char in message:\n",
    "        encrpted_char = char\n",
    "        if char in mapping:\n",
    "            encrpted_char = mapping[char]\n",
    "        encrpted_message.append(encrpted_char)\n",
    "        \n",
    "    return ''.join(encrpted_message)\n",
    "\n",
    "encoded_message = encode(original_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avsw z kuwpzesj hvs pvujh ebjghzuw um fc izms  pagiiuase bn zw hvs shsjwzhc xsmujs gwe gmhsj  hvs izhhis pngks avzkv z mzii  gwe sysw kgw pss  swqbimse zw hvs zwmzwzhs zffswpzhc um pngksp um avzkv z gf zqwujgwh  gwe avzkv owua fs wuh  z gf mjzqvhswse  gwe gf gphuwzpvse gh xszwq vsjs jghvsj hvgw hvsjs  muj hvsjs zp wu jsgpuw avc vsjs jghvsj hvgw hvsjs  avc wua jghvsj hvgw hvsw  avu vgp nbh fs vsjs  xc avups ujesj  gwe ezjskhzuw vgys hvzp nigks gwe hzfs xssw giiuhhse hu fs  hvs jsfsfxjgwks um g qbsph um  uws egc hvgh ngppshv xc'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(message, mapping):\n",
    "    #decoded message\n",
    "    decrypted_message = []\n",
    "    for char in message:\n",
    "        decrypted_char = char\n",
    "        if char in mapping:\n",
    "            decrypted_char = list(mapping.keys())[list(mapping.values()).index(char)]\n",
    "        decrypted_message.append(decrypted_char)\n",
    "        \n",
    "    return ''.join(decrypted_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Genetic Algorithm<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolutionary Algorithm to decode the message\n",
    "\n",
    "# Initialize \n",
    "dna_pool = []\n",
    "for _ in range(20): #20 DNA strings\n",
    "    dna = list(string.ascii_lowercase)\n",
    "    random.shuffle(dna)\n",
    "    dna_pool.append(dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_offspring(dna_pool, n_children):\n",
    "\n",
    "    #create n_children per offspring\n",
    "    offspring = []\n",
    "    \n",
    "    for dna in dna_pool:\n",
    "        for _ in range(n_children):\n",
    "            copy = dna.copy()\n",
    "            j = np.random.randint(len(copy))\n",
    "            k = np.random.randint(len(copy))\n",
    "            \n",
    "            #switch\n",
    "            temp = copy[j]\n",
    "            copy[j] = copy[k]\n",
    "            copy[k] = temp\n",
    "            offspring.append(copy)  \n",
    "    return offspring + dna_pool         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basak\\AppData\\Local\\Temp\\ipykernel_688\\1122369175.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  log_prob = np.log(pi[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 dna2score: -inf best dna2score so far: -1885.4892018096032\n",
      "iter: 100 dna2score: -inf best dna2score so far: -1247.1390424156261\n",
      "iter: 200 dna2score: -inf best dna2score so far: -1164.4394214151\n",
      "iter: 300 dna2score: -inf best dna2score so far: -1026.7290279731951\n",
      "iter: 400 dna2score: -inf best dna2score so far: -998.0539899664259\n",
      "iter: 500 dna2score: -inf best dna2score so far: -979.1312194832418\n",
      "iter: 600 dna2score: -inf best dna2score so far: -963.0919684308092\n",
      "iter: 700 dna2score: -inf best dna2score so far: -963.0919684308092\n",
      "iter: 800 dna2score: -inf best dna2score so far: -963.0919684308092\n",
      "iter: 900 dna2score: -inf best dna2score so far: -963.0919684308092\n"
     ]
    }
   ],
   "source": [
    "num_iters = 1000\n",
    "scores = np.zeros(num_iters)\n",
    "best_dna = None\n",
    "best_map = None\n",
    "best_dna2score = float('-inf') #minus infinity, minimum possible value\n",
    "for i in range(num_iters):\n",
    "    if i > 0:\n",
    "        #get offspring from the current dna pool\n",
    "        dna_pool = evolve_offspring(dna_pool, n_children=3)\n",
    "        \n",
    "    #calculate the dna2score for each dna string\n",
    "    dna2score = {}\n",
    "    for dna in dna_pool:\n",
    "        #populate the mapping dictionary\n",
    "        current_map = {}\n",
    "        for k, v in zip (letters1, dna):\n",
    "            current_map[k] = v\n",
    "            \n",
    "        #decode the message\n",
    "        decoded_message = decode(encoded_message, current_map)\n",
    "        score = get_sentence_probability(decoded_message)\n",
    "        \n",
    "        dna2score[''.join(dna)] = score #list to string to use it in the dictionary\n",
    "        \n",
    "        #keep track of the best dna string\n",
    "        \n",
    "        if score > best_dna2score:\n",
    "            best_dna = dna\n",
    "            best_map = current_map\n",
    "            best_dna2score = score\n",
    "        \n",
    "        \n",
    "    #average dna2score for this iteration\n",
    "    scores[i] = np.mean(list(dna2score.values()))\n",
    "    \n",
    "    #keep the best 5 dna strings\n",
    "    #turn into a list\n",
    "    sorted_dna2score = sorted(dna2score.items(), key=lambda x: x[1], reverse=True) #sort allows us to sort the dictionary by the values\n",
    "    dna_pool = [list(k) for k, v in sorted_dna2score[:5]]\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"iter:\", i, \"dna2score:\", scores[i], \"best dna2score so far:\", best_dna2score)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log likelihood of original message: -963.0919684308092\n",
      "log likelihood of decoded message: -963.0919684308092\n"
     ]
    }
   ],
   "source": [
    "#Use the best mapping to decode the message\n",
    "decoded_message = decode(encoded_message, best_map)\n",
    "\n",
    "\n",
    "print(\"log likelihood of original message:\", get_sentence_probability(decoded_message))\n",
    "print(\"log likelihood of decoded message:\", get_sentence_probability(regex.sub(' ', original_message.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> g \t CORRECT!\n",
      "b -> x \t CORRECT!\n",
      "c -> k \t CORRECT!\n",
      "d -> e \t CORRECT!\n",
      "e -> s \t CORRECT!\n",
      "f -> m \t CORRECT!\n",
      "g -> q \t CORRECT!\n",
      "h -> v \t CORRECT!\n",
      "i -> z \t CORRECT!\n",
      "j -> d \t WRONG!\n",
      "k -> o \t CORRECT!\n",
      "l -> i \t CORRECT!\n",
      "m -> f \t CORRECT!\n",
      "n -> w \t CORRECT!\n",
      "o -> u \t CORRECT!\n",
      "p -> n \t CORRECT!\n",
      "q -> t \t WRONG!\n",
      "r -> j \t CORRECT!\n",
      "s -> p \t CORRECT!\n",
      "t -> h \t CORRECT!\n",
      "u -> b \t CORRECT!\n",
      "v -> y \t CORRECT!\n",
      "w -> a \t CORRECT!\n",
      "x -> l \t CORRECT!\n",
      "y -> c \t CORRECT!\n",
      "z -> r \t WRONG!\n"
     ]
    }
   ],
   "source": [
    "#Which letters are wrong?\n",
    "\n",
    "for true, v in mapping.items():\n",
    "    guess = best_map[true]\n",
    "    if guess != true:\n",
    "        print(true, '->', guess, '\\t', 'CORRECT!' if guess == v else 'WRONG!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded message:\n",
      " when i consider the short duration of my life  swallowed up in the\n",
      "eternity before and after  the little space which i fill  and even can\n",
      "see  engulfed in the infinite immensity of spaces of which i am\n",
      "ignorant  and which know me not  i am frightened  and am astonished at\n",
      "being here rather than there  for there is no reason why here rather\n",
      "than there  why now rather than then  who has put me here  by whose\n",
      "order  and direction have this place and time been allotted to me  the\n",
      "remembrance of a guest of  one day that passeth by\n",
      "\n",
      "True message:\n",
      " When I consider the short duration of my life, swallowed up in the\n",
      "eternity before and after, the little space which I fill, and even can\n",
      "see, engulfed in the infinite immensity of spaces of which I am\n",
      "ignorant, and which know me not, I am frightened, and am astonished at\n",
      "being here rather than there; for there is no reason why here rather\n",
      "than there, why now rather than then. Who has put me here? By whose\n",
      "order  and direction have this place and time been allotted to me? The\n",
      "remembrance of a guest of  one day that passeth by\n"
     ]
    }
   ],
   "source": [
    "#Print the decoded message\n",
    "print(\"Decoded message:\\n\", textwrap.fill(decoded_message))\n",
    "\n",
    "print(\"\\nTrue message:\\n\", textwrap.fill(original_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48568052eec3e48bec5163d0241420ad0cb3738ffc0c56fbb083086b8e264995"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
